{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignement 1 Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible solutions for the assignment questions.\n",
    "Input-output types could be different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment: Working with Dependency Graphs (Parses)\n",
    "\n",
    "The objective of the assignment is to learn how to work with dependency graphs by defining functions.\n",
    "\n",
    "Read [spaCy documentation on dependency parser](https://spacy.io/api/dependencyparser) to learn provided methods.\n",
    "\n",
    "Define functions to:\n",
    "- extract a path of dependency relations from the ROOT to a token\n",
    "- extract subtree of a dependents given a token\n",
    "- check if a given list of tokens (segment of a sentence) forms a subtree\n",
    "- identify head of a span, given its tokens\n",
    "- extract sentence subject, direct object and indirect object spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's import spacy & create a doc\n",
    "import spacy\n",
    "from spacy.tokens import Doc, Span, Token\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "txt = \"I saw a man with a telescope.\"\n",
    "doc = nlp(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.1\n",
    "Function to extract a path of dependency relations from the ROOT to a token.\n",
    "\n",
    "The objective is to learn to traverse a dependency parse. \n",
    "\n",
    "Also useful as a feature for some sequence labeling tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_dependency_path(token, root=None):\n",
    "        \"\"\"\n",
    "        Get dependency path of a token: list of dependency relations from ROOT\n",
    "        :param token: spaCy Token\n",
    "        :type token: Token\n",
    "        :return:\n",
    "        :rtype: list\n",
    "        \"\"\"\n",
    "        root = 'ROOT' if root is None else root\n",
    "        path = []\n",
    "        while token.dep_ != root:\n",
    "            path.append(token.dep_)\n",
    "            token = token.head\n",
    "        return [root] + list(reversed(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ROOT', 'nsubj']\n",
      "['ROOT']\n",
      "['ROOT', 'dobj', 'det']\n",
      "['ROOT', 'dobj']\n",
      "['ROOT', 'prep']\n",
      "['ROOT', 'prep', 'pobj', 'det']\n",
      "['ROOT', 'prep', 'pobj']\n",
      "['ROOT', 'punct']\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "for sent in doc.sents:\n",
    "    for token in sent:\n",
    "        path = get_token_dependency_path(token)\n",
    "        print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.2\n",
    "Function to extract subtree of a dependents given a token.\n",
    "\n",
    "Required for other questions.\n",
    "\n",
    "several solutions possible:\n",
    "1. use `subtree`\n",
    "2. use `left_edge`, `right_edge`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_subtree_span(token, doc):\n",
    "    \"\"\"\n",
    "    Get span of the dependency subtree of a token\n",
    "    :param token: spaCy Token or string\n",
    "    :param doc: spaCy Doc\n",
    "    :type doc: Doc\n",
    "    :return:\n",
    "    :rtype: Span\n",
    "    \"\"\"\n",
    "    if type(token) is str:\n",
    "        # need to find it in doc; get the first\n",
    "        for t in doc:\n",
    "            if t.text == token:\n",
    "                token = t\n",
    "                break\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    if type(token) is Token:\n",
    "        # return Span(doc, token.left_edge.i, token.right_edge.i + 1)\n",
    "        subtree = list(token.subtree)  # generator object\n",
    "        return doc[subtree[0].i:subtree[-1].i + 1]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a telescope\n",
      "with a telescope\n",
      "I\n",
      "I saw a man with a telescope.\n",
      "a\n",
      "a man\n",
      "with a telescope\n",
      "a\n",
      "a telescope\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "print(get_token_subtree_span(\"telescope\", doc))\n",
    "print(get_token_subtree_span(\"with\", doc))\n",
    "\n",
    "# spacy tokens\n",
    "for token in doc:\n",
    "    print(get_token_subtree_span(token, doc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.3\n",
    "Function to check if a given list of tokens (segment of a sentence) forms a subtree\n",
    "\n",
    "In Q1.2 we are extracting the subtrees of each token, the solution is to check if any of this subtrees match the token list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains(doc, tokens):\n",
    "    \"\"\"\n",
    "    if token is not a contiguous within doc, it cannot be a substring\n",
    "    :param doc:\n",
    "    :type doc: spaCy Doc\n",
    "    :param tokens:\n",
    "    :type tokens: list\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    for i in range(len(doc) - len(tokens) + 1):\n",
    "        for j in range(len(tokens)):\n",
    "            if doc[i+j] != tokens[j]:\n",
    "                break\n",
    "        else:\n",
    "            return (i, i + len(tokens))\n",
    "    return False\n",
    "\n",
    "\n",
    "def is_subtree(tokens, doc):\n",
    "    \"\"\"\n",
    "    Return True if a given list of tokens forms a subtree in the dependency parse of a sentence (doc)\n",
    "    :param tokens: list of strings\n",
    "    :type tokens: list\n",
    "    :param doc: spaCy Doc\n",
    "    :type doc: Doc\n",
    "    :return:\n",
    "    :rtype: bool\n",
    "    \"\"\"\n",
    "    # get beginning and end indices of tokens in a doc\n",
    "    indices = contains([t.text for t in doc], tokens)\n",
    "    \n",
    "    if indices is False:\n",
    "        return False\n",
    "    \n",
    "    for sent in doc.sents:\n",
    "        for token in sent:\n",
    "            subtree = get_token_subtree_span(token, doc)\n",
    "            st_indices = subtree[0].i, subtree[-1].i + 1  # to be compatibe with indices\n",
    "            if indices == st_indices:\n",
    "                return True\n",
    "            \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices: (2, 5)\n",
      "a man with\n"
     ]
    }
   ],
   "source": [
    "# let's test contains\n",
    "print(\"indices:\", contains(txt.split(), [\"a\", \"man\", \"with\"]))\n",
    "print(doc[2:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(is_subtree([\"a\", \"man\", \"telescope\"], doc))  # not contiguous\n",
    "print(is_subtree([\"a\", \"man\", \"with\"], doc))       # not a subtree\n",
    "print(is_subtree([\"a\", \"man\"], doc))               # subtree\n",
    "print(is_subtree([\"saw\", \"a\", \"man\"], doc))        # not a subtree\n",
    "print(is_subtree([\"with\", \"a\", \"telescope\"], doc))               # subtree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.4\n",
    "Function to identify head of a span, given its tokens\n",
    "\n",
    "The objective is to learn relation between Span, Doc, etc. and how to convert one to another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_span_head(span):\n",
    "    \"\"\"\n",
    "    Get head of a span\n",
    "    :param span:\n",
    "    :param doc:\n",
    "    :type doc: Doc\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if type(span) is Span:\n",
    "        span = span\n",
    "    elif type(span) is Doc:\n",
    "        span = span[0:]\n",
    "    elif type(span) is str:\n",
    "        span = nlp(span)[0:]\n",
    "    elif type(span) is list:\n",
    "        span = nlp(\" \".join(span))\n",
    "    else:\n",
    "        raise TypeError\n",
    "    return span.root           \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man\n",
      "man\n",
      "saw\n"
     ]
    }
   ],
   "source": [
    "print(get_span_head(\"a man with\"))\n",
    "print(get_span_head(doc[2:]))\n",
    "print(get_span_head(doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.5\n",
    "Function to extract sentence subject, direct object and indirect object spans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_args(sent):\n",
    "    sent = sent if type(sent) in [Doc, Span] else nlp(sent)\n",
    "    args = {}\n",
    "    for token in sent:\n",
    "        # print(token.dep_)\n",
    "        if token.dep_ == 'nsubj':\n",
    "            args[\"subj\"] = get_token_subtree_span(token, sent).text\n",
    "        elif token.dep_ in ['dobj', 'obj']:  # mean the same, spacy uses dobj\n",
    "            args[\"dobj\"] = get_token_subtree_span(token, sent).text\n",
    "        elif token.dep_ in ['iobj', 'dative']:  # mean the same, spacy uses dative\n",
    "            args[\"iobj\"] = get_token_subtree_span(token, sent).text\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subj': 'I', 'dobj': 'a man'}\n",
      "{'subj': 'she', 'iobj': 'me', 'dobj': 'a book'}\n"
     ]
    }
   ],
   "source": [
    "print(get_sentence_args(doc))\n",
    "print(get_sentence_args(\"she gave me a book\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assigment is in the intersection of Named Entity Recognition and Dependency Parsing.\n",
    "\n",
    "0. Evaluate spaCy NER on CoNLL 2003 data (provided)\n",
    "    - report token-level performance (per class and total)\n",
    "        - accuracy of correctly recognizing all tokens that belong to named entities (i.e. tag-level accuracy) \n",
    "    - report CoNLL chunk-level performance (per class and total);\n",
    "        - precision, recall, f-measure of correctly recognizing all the named entities in a chunk per class and total  \n",
    "\n",
    "1. Grouping of Entities.\n",
    "Write a function to group recognized named entities using `noun_chunks` method of [spaCy](https://spacy.io/usage/linguistic-features#noun-chunks). Analyze the groups in terms of most frequent combinations (i.e. NER types that go together). \n",
    "\n",
    "2. One of the possible post-processing steps is to fix segmentation errors.\n",
    "Write a function that extends the entity span to cover the full noun-compounds. Make use of `compound` dependency relation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to import conll\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../src/'))\n",
    "\n",
    "from conll import evaluate, read_corpus_conll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('SOCCER', 'NN', 'B-NP', 'O'), ('-', ':', 'O', 'O'), ('JAPAN', 'NNP', 'B-NP', 'B-LOC'), ('GET', 'VB', 'B-VP', 'O'), ('LUCKY', 'NNP', 'B-NP', 'O'), ('WIN', 'NNP', 'I-NP', 'O'), (',', ',', 'O', 'O'), ('CHINA', 'NNP', 'B-NP', 'B-PER'), ('IN', 'IN', 'B-PP', 'O'), ('SURPRISE', 'DT', 'B-NP', 'O'), ('DEFEAT', 'NN', 'I-NP', 'O'), ('.', '.', 'O', 'O')]\n"
     ]
    }
   ],
   "source": [
    "# reading corpus\n",
    "tst = read_corpus_conll('conll2003/test.txt', fs=\" \")\n",
    "print(tst[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conll2sent_str(conll_segment):\n",
    "    return \" \".join([t[0] for t in conll_segment])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are going to work only with these entities, removing the rest\n",
    "# alternatively we can convert them\n",
    "spacy2conll = {\n",
    "    \"PERSON\": \"PER\",\n",
    "    \"GPE\": \"LOC\",\n",
    "    \"ORG\": \"ORG\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_label(iob, label, oos=None):\n",
    "    oos = 'O' if oos is None else oos\n",
    "    if iob == oos:\n",
    "        return oos\n",
    "    elif label not in spacy2conll:\n",
    "        return oos\n",
    "    else:\n",
    "        return \"-\".join([iob, spacy2conll.get(label)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's define function to get proper output\n",
    "def doc2conll(doc):\n",
    "    out = []\n",
    "    for t in doc:\n",
    "        out.append((t.text, join_label(t.ent_iob_, t.ent_type_)))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 1\n",
    "First solution to tokenization issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokenizer import Tokenizer\n",
    "\n",
    "nlp1 = spacy.load(\"en\")\n",
    "nlp1.tokenizer = Tokenizer(nlp1.vocab)  # to use white space tokenization (generally a bad idea for unknown data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing test set\n",
    "out1 = []\n",
    "for seg in tst:\n",
    "    seg_txt = conll2sent_str(seg)\n",
    "    seg_doc = nlp1(seg_txt)\n",
    "    out1.append(doc2conll(seg_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p</th>\n",
       "      <th>r</th>\n",
       "      <th>f</th>\n",
       "      <th>s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LOC</th>\n",
       "      <td>0.795</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.725</td>\n",
       "      <td>1668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PER</th>\n",
       "      <td>0.674</td>\n",
       "      <td>0.542</td>\n",
       "      <td>0.601</td>\n",
       "      <td>1617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MISC</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORG</th>\n",
       "      <td>0.431</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.344</td>\n",
       "      <td>1661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>0.648</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.521</td>\n",
       "      <td>5648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           p      r      f     s\n",
       "LOC    0.795  0.665  0.725  1668\n",
       "PER    0.674  0.542  0.601  1617\n",
       "MISC   1.000  0.000  0.000   702\n",
       "ORG    0.431  0.286  0.344  1661\n",
       "total  0.648  0.436  0.521  5648"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "res1 = evaluate(tst, out1)\n",
    "pd_tbl = pd.DataFrame().from_dict(res1, orient='index')\n",
    "pd_tbl.round(decimals=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.81      0.68      0.74      1668\n",
      "      B-MISC       0.00      0.00      0.00       702\n",
      "       B-ORG       0.49      0.33      0.39      1661\n",
      "       B-PER       0.72      0.58      0.64      1617\n",
      "       I-LOC       0.58      0.50      0.54       257\n",
      "      I-MISC       0.00      0.00      0.00       216\n",
      "       I-ORG       0.40      0.55      0.47       835\n",
      "       I-PER       0.69      0.75      0.72      1156\n",
      "           O       0.94      0.98      0.96     38554\n",
      "\n",
      "    accuracy                           0.89     46666\n",
      "   macro avg       0.52      0.48      0.50     46666\n",
      "weighted avg       0.87      0.89      0.88     46666\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/unitn/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# token-level performances (ignoring zero division for misc)\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "hyp_list = [tok[-1] for seg in out1 for tok in seg]\n",
    "ref_list = [tok[-1] for seg in tst  for tok in seg]\n",
    "print(classification_report(ref_list, hyp_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 2\n",
    "Second solution, using `whitespace_`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc2conll_merge(doc):\n",
    "    out = []\n",
    "    text = \"\"\n",
    "    iob_ = []\n",
    "    ent_ = []\n",
    "    for t in doc:\n",
    "        text += t.text\n",
    "        iob_.append(t.ent_iob_)\n",
    "        ent_.append(t.ent_type_) \n",
    "        \n",
    "        if len(t.whitespace_) > 0 or t.i == len(doc) - 1:\n",
    "            if len(ent_) == 1:\n",
    "                tag = join_label(iob_[0], ent_[0])\n",
    "            else:\n",
    "                # you can use your logic here\n",
    "                # check if it is all 'O'\n",
    "                if all([x == 'O' for x in iob_]):\n",
    "                    tag = 'O'\n",
    "                else:\n",
    "                    # entity which is not 'O', but all tokens are the same\n",
    "                    if len(set(ent_)) == 1:\n",
    "                        tag = join_label('B', ent_[0])\n",
    "                    else:\n",
    "                        # take the last, since it is the head usually\n",
    "                        tag = join_label('B', ent_[-1])\n",
    "                \n",
    "            out.append((text, tag))\n",
    "            \n",
    "            text = \"\"\n",
    "            iob_ = []\n",
    "            ent_ = []\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing test set\n",
    "nlp2 = spacy.load(\"en\")\n",
    "out2 = []\n",
    "for seg in tst:\n",
    "    seg_txt = conll2sent_str(seg)\n",
    "    seg_doc = nlp2(seg_txt)\n",
    "    out2.append(doc2conll_merge(seg_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.81      0.68      0.74      1668\n",
      "      B-MISC       0.00      0.00      0.00       702\n",
      "       B-ORG       0.51      0.33      0.40      1661\n",
      "       B-PER       0.72      0.60      0.66      1617\n",
      "       I-LOC       0.63      0.50      0.56       257\n",
      "      I-MISC       0.00      0.00      0.00       216\n",
      "       I-ORG       0.42      0.55      0.47       835\n",
      "       I-PER       0.72      0.75      0.73      1156\n",
      "           O       0.94      0.98      0.96     38554\n",
      "\n",
      "    accuracy                           0.90     46666\n",
      "   macro avg       0.53      0.49      0.50     46666\n",
      "weighted avg       0.87      0.90      0.88     46666\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hyp_list = [tok[-1] for seg in out2 for tok in seg]\n",
    "print(classification_report(ref_list, hyp_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p</th>\n",
       "      <th>r</th>\n",
       "      <th>f</th>\n",
       "      <th>s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LOC</th>\n",
       "      <td>0.802</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.731</td>\n",
       "      <td>1668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PER</th>\n",
       "      <td>0.670</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.612</td>\n",
       "      <td>1617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MISC</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORG</th>\n",
       "      <td>0.442</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.347</td>\n",
       "      <td>1661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>0.655</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.529</td>\n",
       "      <td>5648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           p      r      f     s\n",
       "LOC    0.802  0.671  0.731  1668\n",
       "PER    0.670  0.562  0.612  1617\n",
       "MISC   1.000  0.000  0.000   702\n",
       "ORG    0.442  0.285  0.347  1661\n",
       "total  0.655  0.443  0.529  5648"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2 = evaluate(tst, out2)\n",
    "pd_tbl = pd.DataFrame().from_dict(res2, orient='index')\n",
    "pd_tbl.round(decimals=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_ner(doc):\n",
    "    out = []\n",
    "    for nc in doc.noun_chunks:\n",
    "        group = []\n",
    "        for ent in nc.ents:\n",
    "            group.append(ent.label_)\n",
    "        out.append(group)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'': 5992, 'GPE': 1232, 'PERSON': 1024, 'ORG': 826, 'DATE': 515, 'CARDINAL': 358, 'NORP': 294, 'ORDINAL': 87, 'EVENT': 55, 'MONEY': 51, 'PERCENT': 51, 'LOC': 48, 'NORP+PERSON': 45, 'QUANTITY': 45, 'TIME': 41, 'CARDINAL+PERSON': 31, 'GPE+PERSON': 29, 'ORG+PERSON': 28, 'FAC': 22, 'CARDINAL+NORP': 14, 'GPE+GPE': 13, 'CARDINAL+GPE': 13, 'CARDINAL+ORG': 13, 'WORK_OF_ART': 12, 'GPE+ORG': 12, 'PRODUCT': 10, 'DATE+EVENT': 9, 'NORP+ORG': 8, 'DATE+TIME': 8, 'ORG+ORG': 7, 'PERSON+PERSON': 6, 'CARDINAL+CARDINAL': 5, 'ORG+GPE': 5, 'NORP+NORP': 5, 'DATE+NORP': 5, 'PERSON+GPE': 4, 'DATE+PERSON': 4, 'GPE+NORP': 4, 'ORG+DATE': 4, 'GPE+FAC': 4, 'ORDINAL+CARDINAL': 3, 'CARDINAL+DATE': 3, 'LAW': 3, 'PERSON+ORDINAL': 3, 'DATE+ORG': 3, 'NORP+ORDINAL': 3, 'GPE+CARDINAL': 3, 'ORG+NORP': 3, 'GPE+LOC': 3, 'GPE+DATE': 3, 'QUANTITY+ORDINAL': 3, 'LANGUAGE': 3, 'CARDINAL+EVENT': 2, 'ORDINAL+NORP': 2, 'DATE+FAC': 2, 'ORDINAL+PERSON': 2, 'GPE+ORDINAL': 2, 'ORDINAL+GPE': 2, 'MONEY+CARDINAL+CARDINAL': 2, 'ORG+ORDINAL': 2, 'EVENT+CARDINAL': 2, 'ORDINAL+EVENT': 2, 'NORP+GPE': 1, 'NORP+DATE+ORG': 1, 'ORDINAL+DATE': 1, 'EVENT+PERSON': 1, 'ORG+QUANTITY': 1, 'TIME+PERSON': 1, 'TIME+CARDINAL+PERSON': 1, 'QUANTITY+GPE': 1, 'CARDINAL+ORDINAL': 1, 'MONEY+EVENT': 1, 'DATE+DATE': 1, 'CARDINAL+DATE+PERSON': 1, 'CARDINAL+PERSON+PERSON': 1, 'CARDINAL+PERSON+DATE': 1, 'DATE+ORG+GPE': 1, 'MONEY+ORG': 1, 'PERSON+ORG': 1, 'LOC+DATE': 1, 'GPE+CARDINAL+NORP': 1, 'CARDINAL+CARDINAL+NORP': 1, 'NORP+ORG+DATE': 1, 'LOC+ORDINAL': 1, 'MONEY+PERSON': 1, 'PRODUCT+PERSON': 1, 'NORP+LOC': 1, 'CARDINAL+CARDINAL+ORG': 1, 'MONEY+DATE': 1, 'NORP+QUANTITY': 1, 'NORP+TIME': 1, 'GPE+DATE+ORG': 1, 'DATE+CARDINAL': 1, 'NORP+DATE': 1, 'NORP+NORP+PERSON': 1, 'CARDINAL+TIME': 1, 'MONEY+MONEY': 1, 'CARDINAL+MONEY': 1, 'ORG+EVENT': 1, 'MONEY+CARDINAL': 1, 'PERSON+QUANTITY': 1, 'CARDINAL+PRODUCT': 1, 'DATE+NORP+PERSON': 1, 'ORG+WORK_OF_ART': 1, 'GPE+ORDINAL+PERSON': 1, 'CARDINAL+LOC': 1, 'ORG+CARDINAL+GPE': 1, 'PERSON+CARDINAL+GPE': 1, 'FAC+GPE': 1, 'CARDINAL+WORK_OF_ART': 1, 'CARDINAL+CARDINAL+GPE': 1, 'ORG+CARDINAL': 1, 'CARDINAL+PERSON+PERCENT+ORG': 1, 'ORDINAL+TIME': 1, 'QUANTITY+PERSON': 1, 'FAC+PERSON': 1, 'NORP+PRODUCT': 1, 'NORP+PERSON+NORP+PERSON': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "groups = []\n",
    "for seg in tst:\n",
    "    seg_txt = conll2sent_str(seg)\n",
    "    seg_doc = nlp(seg_txt)\n",
    "    chunks = group_ner(seg_doc)\n",
    "    groups.extend(chunks)\n",
    "\n",
    "print(Counter([\"+\".join(g) for g in groups]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Compounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compounds(doc):\n",
    "    # get all tokens in compound dependency relation\n",
    "    compounds = [token for token in doc if token.dep_ == 'compound']\n",
    "    # remove the middle ones to avoid overlaps\n",
    "    compounds = [c for c in compounds if c.i == 0 or doc[c.i - 1].dep_ != 'compound']\n",
    "    # take a slice of doc (i.e. make a span) from token to its head\n",
    "    compounds = [doc[token.i:token.head.i + 1] for token in compounds]\n",
    "    return compounds\n",
    "\n",
    "\n",
    "def get_span_compound(span, doc):\n",
    "    \"\"\"\n",
    "    Get head of a span and return NN compound\n",
    "    :param span:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    span_head = get_span_head(span)\n",
    "    compounds = get_compounds(doc)\n",
    "    \n",
    "    # we are interested in compounds that share the head with the entity,\n",
    "    # otherwise tag changes\n",
    "    compounds = [c for c in compounds if c.root == span.root]\n",
    "\n",
    "    # if there are several, we are taking the shortest (just for safety)\n",
    "    if len(compounds) > 1:\n",
    "        min_span = min(compounds, key=len)\n",
    "        return min_span\n",
    "\n",
    "    return compounds[0] if len(compounds) == 1 else span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entities2compound(doc):\n",
    "    out = doc2conll(doc)\n",
    "    for ent in doc.ents:\n",
    "        nnc = get_span_compound(ent, doc)\n",
    "        if len(nnc) > len(ent):\n",
    "            bos = nnc[0].i   # 1st index of span\n",
    "            eos = nnc[-1].i  # last index of span\n",
    "            # subsequent entities will over-write\n",
    "            for i in range(bos, eos+1):\n",
    "                if i == bos:\n",
    "                    out[i] = (doc[i].text, join_label(\"B\", ent.label_))\n",
    "                else:\n",
    "                    out[i] = (doc[i].text, join_label(\"I\", ent.label_))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for evaluation this needs to be combined with tokenization & conversion to conll (w.r.t. labels and format)\n",
    "hyps = []\n",
    "for seg in tst:\n",
    "    txt = conll2sent_str(seg)\n",
    "    doc = nlp1(txt)\n",
    "    cmp = entities2compound(doc)\n",
    "    hyps.append(cmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p</th>\n",
       "      <th>r</th>\n",
       "      <th>f</th>\n",
       "      <th>s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LOC</th>\n",
       "      <td>0.787</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.712</td>\n",
       "      <td>1668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PER</th>\n",
       "      <td>0.605</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.538</td>\n",
       "      <td>1617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MISC</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORG</th>\n",
       "      <td>0.423</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.337</td>\n",
       "      <td>1661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>0.618</td>\n",
       "      <td>0.413</td>\n",
       "      <td>0.495</td>\n",
       "      <td>5648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           p      r      f     s\n",
       "LOC    0.787  0.649  0.712  1668\n",
       "PER    0.605  0.485  0.538  1617\n",
       "MISC   1.000  0.000  0.000   702\n",
       "ORG    0.423  0.280  0.337  1661\n",
       "total  0.618  0.413  0.495  5648"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res3 = evaluate(tst, hyps)\n",
    "pd_tbl = pd.DataFrame().from_dict(res3, orient='index')\n",
    "pd_tbl.round(decimals=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It performs worse than without post-processing. Though, it has a bit higher recall at token level for `I-PER` and `I-LOC`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.80      0.66      0.73      1668\n",
      "      B-MISC       0.00      0.00      0.00       702\n",
      "       B-ORG       0.48      0.32      0.39      1661\n",
      "       B-PER       0.66      0.53      0.58      1617\n",
      "       I-LOC       0.52      0.51      0.51       257\n",
      "      I-MISC       0.00      0.00      0.00       216\n",
      "       I-ORG       0.40      0.55      0.46       835\n",
      "       I-PER       0.63      0.76      0.69      1156\n",
      "           O       0.94      0.97      0.95     38554\n",
      "\n",
      "    accuracy                           0.89     46666\n",
      "   macro avg       0.49      0.48      0.48     46666\n",
      "weighted avg       0.87      0.89      0.88     46666\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/unitn/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "hyp_list = [tok[-1] for seg in hyps for tok in seg]\n",
    "print(classification_report(ref_list, hyp_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
