{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Language Modeling: Solutions\n",
    "\n",
    "- Natural Language Understanding\n",
    "- Evgeny A. Stepanov\n",
    "- stepanov.evgeny.a@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dan Jurafsky and James H. Martin's __Speech and Language Processing__ ([3rd ed. draft](https://web.stanford.edu/~jurafsky/slp3/)) is advised for reading. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Requirements__\n",
    "\n",
    "- [NL2SparQL4NLU](https://github.com/esrel/NL2SparQL4NLU) dataset\n",
    "\n",
    "    - run `git clone https://github.com/esrel/NL2SparQL4NLU.git`\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provided functions and classes (from the Lab Notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get nbest from dict w.r.t. value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nbest(d, n=1):\n",
    "    \"\"\"\n",
    "    get n max values from a dict\n",
    "    :param d: input dict (values are numbers)\n",
    "    :param n: number of values to get (int)\n",
    "    :return: dict of top n key-values\n",
    "    \"\"\"\n",
    "    return dict(sorted(d.items(), key=lambda item: item[1], reverse=True)[:n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data structure to store ngram counts and probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "\n",
    "    def __init__(self, word=None):\n",
    "        self.word = word\n",
    "        self.children = {}\n",
    "        self.count = 0\n",
    "        \n",
    "    def __set__(self, instance, value):\n",
    "        self.instance = value\n",
    "\n",
    "    def __get__(self, instance, owner):\n",
    "        return self.instance\n",
    "\n",
    "\n",
    "class Trie(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.root = Node('*')\n",
    "        self.error = Node()\n",
    "    \n",
    "    def __set__(self, instance, value):\n",
    "        self.instance = value\n",
    "\n",
    "    def __get__(self, instance, owner):\n",
    "        return self.instance\n",
    "\n",
    "    def add(self, sequence):\n",
    "        node = self.root\n",
    "        node.count += 1  # total count\n",
    "        for word in sequence:\n",
    "            node.children[word] = node.children.setdefault(word, Node(word))\n",
    "            node = node.children[word]\n",
    "            node.count += 1\n",
    "\n",
    "    def get(self, sequence):\n",
    "        node = self.root\n",
    "        for word in sequence:\n",
    "            node = node.children.get(word, self.error)\n",
    "        return node\n",
    "    \n",
    "    def traverse(self, node=None, sequence=[]):\n",
    "        node = self.root if not node else node\n",
    "        \n",
    "        if not node.children:\n",
    "            yield sequence\n",
    "\n",
    "        for word, n in node.children.items():\n",
    "            sequence.append(word)\n",
    "            yield from self.traverse(n, sequence)\n",
    "            sequence.pop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting Ngrams and Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract ngrams from a sequence (list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrams(sequence, n=2):\n",
    "    \"\"\"\n",
    "    returns ngrams as a list-of-lists of sequence elements\n",
    "    :param sequence: list of elements\n",
    "    :param n: ngram size to extract\n",
    "    :return: list of ngrams\n",
    "    \"\"\"\n",
    "    return [sequence[i:i+n] for i in range(len(sequence) - n + 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count ngrams in corpus (list-of-lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngramcount(corpus, n=2):\n",
    "    \"\"\"\n",
    "    count ngrams in a corpus and stores as a Trie\n",
    "    :param corpus: list-of-lists\n",
    "    :param n: ngram size to count\n",
    "    :param glue: symbol for ngram concatenation into string\n",
    "    :return: dict of ngram frequencies\n",
    "    \"\"\"\n",
    "    counts = Trie()\n",
    "    counts.size = n  # meta-info: ngram-size\n",
    "    for sent in corpus:\n",
    "        for ngram in ngrams(sent, n=n):\n",
    "            counts.add(ngram) \n",
    "    return counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute probabilities from ngram counts\n",
    "- flags to:\n",
    "    - use log probabilities (default: True)\n",
    "    - use add one smoothing (default: False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngramprobs(counts, logs=True, smoothing=False):\n",
    "    \"\"\"\n",
    "    compute ngram probabilities from frequency counts\n",
    "    :param counts: counts trie\n",
    "    :param logs: if to compute log-probabilities\n",
    "    :param smoothing: if to use add 1 smoothing\n",
    "    :return: trie augmented with probabilties\n",
    "    \"\"\"\n",
    "    from math import log\n",
    "    \n",
    "    # set meta-information\n",
    "    counts.logs = logs  # meta-info: log probabilities are used\n",
    "    counts.smoothing = smoothing # meta-info: smoothing true|false\n",
    "    \n",
    "    # add 1 smoothing\n",
    "    v = compute_ngram_vocabulary_size(counts, n = counts.size - 1) if smoothing else 0\n",
    "    a = 1 if smoothing else 0\n",
    "    \n",
    "    # update error probability:\n",
    "    counts.error.probability = log(a / v) if (smoothing and logs) else 0.0\n",
    "    \n",
    "    for ngram in counts.traverse(): \n",
    "        n = counts.get(ngram)       # get ngram node\n",
    "        p = counts.get(ngram[:-1])  # get parent node\n",
    "        prob = (n.count + a) / (p.count + v)\n",
    "        n.probability = log(prob) if logs else prob\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to compute ngram vocabulary size for add one smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ngram_vocabulary_size(counts, n=1):\n",
    "    return len(set([\"+\".join(ngram[:n]) for ngram in counts.traverse()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to convert log probabilities to raw probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logp2p(value):\n",
    "    from math import exp\n",
    "    return exp(value) if value else 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus Pre-Processing\n",
    "- Pre-process training and test sets using [corpus and lexicon preprocessing functions](corpus_pp_python.ipynb) to:\n",
    "    - add sentence begin & end tags\n",
    "    - handle unknown words (e.g. frequency cut-off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus(corpus_file):\n",
    "    \"\"\"\n",
    "    read corpus into a list-of-lists, splitting sentences into tokens by space (' ')\n",
    "    :param corpus_file: corpus file in sentence-per-line format (tokenized)\n",
    "    :return: corpus as list of lists\n",
    "    \"\"\"\n",
    "    return [line.strip().split() for line in open(corpus_file, 'r')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn='NL2SparQL4NLU.trn.data'\n",
    "tst='NL2SparQL4NLU.tst.data'\n",
    "\n",
    "trn_data = read_corpus(trn)\n",
    "tst_data = read_corpus(tst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ngram Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counting ngrams & Reporting most frequent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<s>+what': 511, '<s>+show': 450, 'show+me': 377, 'movies+</s>': 333, '<unk>+</s>': 284}\n"
     ]
    }
   ],
   "source": [
    "counts = ngramcount(trn_data, n=2)\n",
    "\n",
    "print(nbest({\"+\".join(ngram): counts.get(ngram).count for ngram in counts.traverse()}, n=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Querying Ngrams & Reporting Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30642504118616143\n",
      "0.3582089552238806\n",
      "0.0\n",
      "['italy', '</s>'] 0.6\n",
      "['italy', 'make'] 0.2\n",
      "['italy', 'in'] 0.2\n"
     ]
    }
   ],
   "source": [
    "probs = ngramprobs(counts, logs=False)\n",
    "\n",
    "print(probs.get(['of', 'the']).probability)\n",
    "print(probs.get(['is', 'the']).probability)\n",
    "print(probs.get(['the', 'play']).probability)  # not in training data\n",
    "\n",
    "for ngram in probs.traverse(node=probs.get(['italy']), sequence=['italy']):\n",
    "    print(ngram, probs.get(ngram).probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ngram Sequence Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(model, sentence):\n",
    "    \"\"\"\n",
    "    score a sentence given ngram model\n",
    "    :param model: trie ngram model\n",
    "    :param sentence: sentence as a list of tokens\n",
    "    :return: log probability\n",
    "    \"\"\"\n",
    "    from numpy import prod\n",
    "    probs = [model.get(ngram).probability for ngram in ngrams(sentence, model.size)]\n",
    "    return sum(probs) if model.logs else prod(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.60719558392048e-07\n",
      "0.0\n",
      "1.0876422746511928e-06\n"
     ]
    }
   ],
   "source": [
    "sent1 = ['<s>', 'star', 'of', 'twilight', '</s>']\n",
    "sent2 = ['<s>', 'star', 'of', 'thor', '</s>']  ## not in training data\n",
    "sent3 = ['<s>', 'star', 'of', '<unk>', '</s>']\n",
    "\n",
    "print(score(probs, sent1))\n",
    "print(score(probs, sent2))\n",
    "print(score(probs, sent3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ngram Sequence Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, bos='<s>', eos='</s>'):\n",
    "    \"\"\"\n",
    "    generate a random sequence from ngram model\n",
    "    :param model: trie ngram model\n",
    "    :param bos: beginning-of-sentence tag\n",
    "    :param eos: end-of-sentence tag\n",
    "    :return: sentence as list & log probability\n",
    "    \"\"\"\n",
    "    import random\n",
    "    word = bos\n",
    "    sent = [bos]\n",
    "    while word != eos:\n",
    "        c_node = model.get(sent[-(model.size - 1):])\n",
    "        word = random.choice(list(c_node.children.keys()))\n",
    "        sent.append(word)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4.613597629256453e-17): <s> g movies steven spielberg start making how popular japanese in france </s>\n",
      "(1.582749916339163e-18): <s> bring in country the best films by directors in china </s>\n",
      "(7.439710837198544e-15): <s> type of recent pg rating did my kid </s>\n",
      "(4.743777307478727e-09): <s> person who made over street </s>\n",
      "(1.5130332685755095e-05): <s> rated </s>\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    s = generate(probs)\n",
    "    print(\"({}): {}\".format(score(probs, s), \" \".join(s)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-17.936125948586973): <s> star of <unk> </s>\n",
      "(-27.42784311979704): <s> who is in the movie the campaign </s>\n",
      "(-34.34157079825078): <s> list the cast of the movie the campaign </s>\n",
      "(-21.79617068101572): <s> who was in twilight </s>\n",
      "(-16.453029986807024): <s> who is in <unk> </s>\n",
      "(-24.4942619985087): <s> actor from lost </s>\n",
      "(-29.630631881867696): <s> who played in the movie rocky </s>\n",
      "(-32.10468394242209): <s> who played in the movie captain america </s>\n",
      "(-29.33155184726785): <s> cast and crew for in july </s>\n",
      "(-27.049305109495606): <s> who is in movie in july </s>\n"
     ]
    }
   ],
   "source": [
    "# let's use all-on\n",
    "lm = ngramprobs(counts, logs=True, smoothing=True)\n",
    "\n",
    "for sent in tst_data[:10]:\n",
    "    print(\"({}): {}\".format(score(lm, sent), \" \".join(sent)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
